name: adalayers_token
kwargs:
  base_model: "FacebookAI/roberta-large"
  project_dim: 256
  layers_num: 24
  layer_in_dim: 1024
  attention_heads_num: 8
  num_classes: ${dataset.num_classes}
  attention_dropout_prob: 0.3
  freeze_distribution: False
  lambda_distribution_entropy: 0.0
  alpha_distribution: 96
  classes_weights: [0.0292, 0.12183, 0.11771, 0.12196, 0.11923, 0.1215697, 0.121895, 0.123348, 0.1232325]
