defaults:
  - model: adalayers_roberta_large
  - optimization: adam
  - tokenizer_pretrained: adalayers_roberta_large
  - dataset: imdb
  - hydra: common
  - _self_

optimization:
  max_epochs: 128
  batch_size: 128
  batch_size_eval: 128

model:
  restore_artifact: "final_imdb_adalayers_model_best:v0"
  kwargs:
    topk_distribution: 7
    attention_dropout_prob: 0.4
    lambda_distribution_entropy: 0.0

wandb:
  name: ${cat:"final-stage2", ${dataset.name}, ${model.name}}
